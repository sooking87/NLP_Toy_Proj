{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da8786d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f0bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(str):\n",
    "    split_str = str.split(\" \")\n",
    "    return split_str\n",
    "\n",
    "# 새로운 불용어와 기존 불용어 필터링하기\n",
    "\n",
    "\n",
    "def filter_stopwords(tokenized_words, stopwords):\n",
    "    tokenized_filtered = []\n",
    "\n",
    "    for word in tokenized_words:\n",
    "        if word not in stopwords:\n",
    "            tokenized_filtered.append(word)\n",
    "\n",
    "    return tokenized_filtered\n",
    "\n",
    "\n",
    "def word_count(tokenized_data):\n",
    "    word_counter = {}\n",
    "\n",
    "    for i in tokenized_data:\n",
    "        if i in word_counter.keys():\n",
    "            word_counter[i] += 1\n",
    "        else:\n",
    "            word_counter[i] = 1\n",
    "\n",
    "    # 많이 나온 순서대로 정렬\n",
    "\n",
    "    sorted_dict = dict(sorted(word_counter.items(),\n",
    "                              key=operator.itemgetter(1), reverse=True))\n",
    "\n",
    "    return sorted_dict\n",
    "\n",
    "# 가장 상위 20개의 단어 보기\n",
    "\n",
    "\n",
    "def top_30(tokenized_dict):\n",
    "    top_30_words = list(tokenized_dict.items())[:30]\n",
    "    return top_30_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf155b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('believe', 10), ('every', 4), ('somewhere', 2), ('someone', 2), ('time', 2), ('hear', 2), ('newborn', 2), ('baby', 2), ('cry', 2), ('touch', 2), ('leaf', 2), ('see', 2), ('sky', 2), ('know', 2), ('drop', 1), ('rain', 1), ('fall', 1), ('flower', 1), ('grows', 1), ('darkest', 1), ('night', 1), ('candle', 1), ('glow', 1), ('everyone', 1), ('go', 1), ('astray', 1), ('come', 1), ('show', 1), ('way', 1), ('storm', 1)]\n",
      "\n",
      "\n",
      "[('cry', 4), ('feel', 2), ('heartache', 2), ('seem', 2), ('hang', 2), ('around', 2), ('long', 2), ('blue', 2), ('keep', 2), ('getting', 2), ('bluer', 2), ('song', 2), ('remember', 2), ('sunshine', 2), ('found', 2), ('behind', 2), ('cloudy', 2), ('sky', 2), ('let', 2), ('hair', 2), ('go', 2), ('sweetheart', 1), ('sends', 1), ('letter', 1), ('goodbye', 1), ('secret', 1), ('better', 1), ('waking', 1), ('bad', 1), ('dream', 1)]\n",
      "\n",
      "\n",
      "[('patricia', 7), ('lip', 2), ('always', 2), ('want', 2), ('stroll', 2), ('see', 2), ('move', 2), ('charm', 2), ('japan', 2), ('brag', 2), ('geisha', 2), ('care', 2), ('long', 2), ('uncle', 2), ('sam', 2), ('got', 2), ('eye', 2), ('starry', 2), ('sort', 2), ('gleam', 2), ('like', 2), ('million', 2), ('dollar', 2), ('dream', 2), ('come', 2), ('true', 2), ('never', 2), ('lyricskiss', 1), ('mambo', 1), ('chacha', 1)]\n",
      "\n",
      "\n",
      "[('got', 16), ('time', 12), ('money', 10), ('ive', 9), ('youve', 8), ('go', 5), ('honey', 5), ('honky', 4), ('tonkin', 4), ('make', 3), ('night', 2), ('spot', 2), ('dance', 2), ('drink', 2), ('beer', 2), ('wine', 2), ('spread', 2), ('boy', 2), ('run', 2), ('short', 2), ('aint', 1), ('use', 1), ('tarry', 1), ('let', 1), ('start', 1), ('tonight', 1), ('joy', 1), ('right', 1), ('fun', 1), ('baby', 1)]\n",
      "\n",
      "\n",
      "[('always', 4), ('im', 3), ('want', 2), ('blue', 2), ('one', 2), ('stay', 2), ('day', 2), ('love', 2), ('lose', 1), ('honey', 1), ('else', 1), ('youre', 1), ('heart', 1), ('gone', 1), ('alone', 1), ('singing', 1), ('song', 1), ('wanna', 1), ('id', 1), ('happy', 1), ('dear', 1), ('could', 1), ('near', 1), ('forever', 1), ('wed', 1), ('travel', 1), ('far', 1), ('big', 1), ('shinin', 1), ('star', 1)]\n",
      "\n",
      "\n",
      "[('long', 12), ('take', 6), ('would', 3), ('thats', 3), ('stop', 3), ('loving', 3), ('old', 2), ('world', 2), ('stood', 2), ('true', 2), ('count', 1), ('star', 1), ('climb', 1), ('mar', 1), ('itd', 1), ('sea', 1), ('water', 1), ('deep', 1), ('mountain', 1), ('steep', 1), ('since', 1), ('new', 1), ('itll', 1), ('forever', 1), ('day', 1), ('time', 1), ('dear', 1), ('say', 1), ('god', 1), ('love', 1)]\n",
      "\n",
      "\n",
      "[('thought', 11), ('look', 4), ('loved', 2), ('think', 2), ('love', 2), ('im', 2), ('id', 2), ('home', 2), ('today', 1), ('say', 1), ('another', 1), ('wear', 1), ('crown', 1), ('found', 1), ('make', 1), ('world', 1), ('go', 1), ('round', 1), ('watch', 1), ('theyll', 1), ('get', 1), ('within', 1), ('future', 1), ('year', 1), ('new', 1), ('bring', 1), ('tear', 1), ('sure', 1), ('wont', 1), ('help', 1)]\n",
      "\n",
      "\n",
      "[('pal', 7), ('old', 6), ('im', 3), ('heart', 3), ('tonight', 2), ('day', 2), ('face', 2), ('place', 2), ('mine', 2), ('always', 2), ('see', 2), ('find', 2), ('ever', 2), ('lyricssongwriter', 1), ('jimmie', 1), ('rodgers', 1), ('thinking', 1), ('wishing', 1), ('dreaming', 1), ('time', 1), ('gone', 1), ('filled', 1), ('cheer', 1), ('remember', 1), ('night', 1), ('alone', 1), ('sang', 1), ('sweet', 1), ('adeline', 1), ('take', 1)]\n",
      "\n",
      "\n",
      "[('love', 7), ('prove', 6), ('day', 4), ('true', 4), ('thousand', 3), ('way', 3), ('youre', 3), ('blue', 3), ('come', 2), ('darlin', 2), ('one', 2), ('heart', 2), ('please', 2), ('wait', 2), ('therell', 2), ('change', 2), ('swear', 1), ('think', 1), ('past', 1), ('fun', 1), ('darling', 1), ('youve', 1), ('good', 1), ('thats', 1), ('apart', 1), ('someday', 1), ('always', 1), ('stay', 1), ('ive', 1), ('lonesome', 1)]\n",
      "\n",
      "\n",
      "[('gone', 10), ('cry', 2), ('farther', 2), ('lost', 2), ('said', 1), ('ever', 1), ('deceived', 1), ('could', 1), ('count', 1), ('ten', 1), ('guess', 1), ('didnt', 1), ('believe', 1), ('cause', 1), ('look', 1), ('trouble', 1), ('im', 1), ('wont', 1), ('bring', 1), ('back', 1), ('faster', 1), ('train', 1), ('fly', 1), ('track', 1), ('ive', 1), ('every', 1), ('right', 1), ('happy', 1), ('heaven', 1), ('found', 1)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_stopwords = ['ill', 'youll', 'well', 'till', 'shes', 'hes', 'shed', 'hed']\n",
    "\n",
    "df = pd.read_csv(r\"C:\\STUDY\\NLP_Toy_Proj\\pre_processing\\renew_dataset_final.csv\")\n",
    "\n",
    "for i in range(10):\n",
    "    # transform\n",
    "    tokenized_list = to_list(df.loc[i, 'lyrics'])\n",
    "    tokenized_filtered = filter_stopwords(tokenized_list, add_stopwords)\n",
    "    count_dict = word_count(tokenized_filtered)\n",
    "    top_30_list = top_30(count_dict)\n",
    "    print(top_30_list)\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081487e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732fa19d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9586a65c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844cc6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c2fca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2cc78b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3abd50e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5398d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0798744b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4f5f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634a606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "35e0334895c7257ffa902a82750dbe09ec85e290cbc1321a3819ebf1c9410545"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
